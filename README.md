# Neural A\* with Heat Method: Enhancing Path Planning via Geodesic and Vector Field Guidance

## Overview

A new path planning framework combining Heat Method-based Geodesic Guidance (Distance Field + Vector Field) with Gated Fusion on top of the existing Neural A\* algorithm.

**Core Ideas:**

- **Heat Method** (Crane et al., 2017): Computes Geodesic Distance that bypasses obstacles through the heat diffusion equation, and extracts a target direction Vector Field from it
- **Gated Fusion**: Inspired by CGSAG (Ke et al., 2024), dynamically fuses base input (Map, Start, Goal) with Heat Method-based global guidance (Vx, Vy, Dist) using a learnable gate

**Differences from Neural A\*:**

| Aspect              | Neural A\*               | Ours                                       |
| ------------------- | ------------------------ | ------------------------------------------ |
| Encoder Input       | 3ch (Map + Start + Goal) | 7ch (+ Vx, Vy, Dist, Reachable)            |
| Additional Guidance | None                     | Heat Method (Geodesic Dist + Vector Field) |
| Feature Fusion      | Single Branch            | 2-Branch + Multi-Scale Gate                |

### Architecture

This project combines the core ideas from both research works:

**1. Heat Method → Geodesic Guidance Generation**

- Computes **Geodesic Distance Field** by diffusing heat from the goal point
- Generates **Vector Guidance Field (Vx, Vy)** by normalizing the gradient of the distance
- These fields provide **global information** representing the "shortest direction to the goal"

**2. Gated Fusion → Base/Heat Information Fusion**

- **Base Branch**: Learns local obstacle patterns from the map image (CNN/U-Net)
- **Heat Branch**: Processes global directional information generated by the Heat Method
- **Learnable Gate**: Adaptively fuses the outputs of both branches according to the situation
  - `Output = Gate × Heat + (1 - Gate) × Base`

**Gate Interpretation:**

- Gate ≈ 1 (Red): Trust Heat info (complex U-shaped obstacles)
- Gate ≈ 0 (Blue): Trust Base info (narrow gaps, obstacle edges)
- Gate ≈ 0.5 (Yellow): Balanced (open space)

**3. Overall Pipeline**

```
Input: Map + Start + Goal + [Vx, Vy, Dist, Reachable]
         ↓
    Gated Encoder (Base Branch ⊕ Heat Branch)
         ↓
      Cost Map
         ↓
  Differentiable A* Search
         ↓
    Predicted Path
```

### Training Modes

| Mode           | Input Channels | Configuration                                   | Description                           |
| -------------- | -------------- | ----------------------------------------------- | ------------------------------------- |
| `vanilla(A*)`  | -              | -                                               | No training (Baseline for comparison) |
| `neural_astar` | 3              | Map + Start + Goal                              | Original Neural A\*                   |
| `ours`         | 7              | Map + Start + Goal + Vx + Vy + Dist + Reachable | Gated Fusion Neural A\*               |

---

## Installation

### Create Conda Environment

```bash
conda env create -f environment.yml
conda activate neural-astar
```

### Install Package

```bash
pip install -e .
```

---

## Usage

### 1. Dataset Preprocessing (Apply Heat Method)

Add Geodesic Guidance Field and Vector Guidance Field to existing datasets:

```bash
# 32x32 maze
python heat_method/preprocessing.py \
    --data_path data/maze/mazes_032_moore_c8.npz \
    --output_path data/maze_preprocessed/mazes_032_moore_c8_ours.npz

# 64x64 mixed maze
python heat_method/preprocessing.py \
    --data_path data/maze/mixed_064_moore_c16.npz \
    --output_path data/maze_preprocessed/mixed_064_moore_c16_ours.npz
```

**NPZ File Structure:**

| Key Name            | Shape          | Description                                  |
| ------------------- | -------------- | -------------------------------------------- |
| `arr_0`~`arr_3`     | Original data  | Train (800): Map, Goal, OptPolicy, OptDist   |
| `arr_4`~`arr_7`     | Original data  | Valid (100): Same as above                   |
| `arr_8`~`arr_11`    | Original data  | Test (100~400): Same as above                |
| `{split}_vx`        | `(N, 1, H, W)` | X-direction vector field (toward the goal)   |
| `{split}_vy`        | `(N, 1, H, W)` | Y-direction vector field (toward the goal)   |
| `{split}_dist`      | `(N, 1, H, W)` | Geodesic Distance (normalized, 0~1)          |
| `{split}_reachable` | `(N, 1, H, W)` | Reachability mask (1: reachable, 0: blocked) |

> `{split}` = `train`, `valid`, `test`

### 2. Training

```bash
# Neural A* (Original)
python scripts/train.py mode=neural_astar encoder.arch=CNN \
    dataset=data/maze_preprocessed/mixed_064_moore_c16_ours

# Ours with Gated Fusion (CNN-based)
python scripts/train.py mode=ours encoder.arch=GatedCNN \
    dataset=data/maze_preprocessed/mixed_064_moore_c16_ours

# Ours with Gated Fusion (U-Net-based)
python scripts/train.py mode=ours encoder.arch=GatedUnet \
    dataset=data/maze_preprocessed/mixed_064_moore_c16_ours
```

### 3. Model Comparison Evaluation

Compare the performance of trained models on the test set:

```bash
# 32x32 dataset
python scripts/compare_models.py --dataset data/maze_preprocessed/mazes_032_moore_c8_ours

# 64x64 dataset
python scripts/compare_models.py --dataset data/maze_preprocessed/mixed_064_moore_c16_ours
```

**Evaluation Metrics:**

| Metric      | Description                                               |
| ----------- | --------------------------------------------------------- |
| **Opt (%)** | Optimal path achievement ratio (higher is better)         |
| **Exp (%)** | Search node reduction rate vs. Vanilla (higher is better) |
| **Hmean**   | Harmonic mean of Opt and Exp (higher is bette)            |

### 4. Visualization (GIF Generation)

Generate GIFs comparing the search process of A\*, Neural A\*, and Ours models:

```bash
# Problem 0 from 32x32 dataset
python scripts/create_comparison_gif.py \
    dataset=data/maze_preprocessed/mazes_032_moore_c8_ours \
    problem_id=0 resultdir=results

# Problem 10 from 64x64 dataset
python scripts/create_comparison_gif.py \
    dataset=data/maze_preprocessed/mixed_064_moore_c16_ours \
    problem_id=10 resultdir=results
```

**Main Options:**

| Option       | Default    | Description                             |
| ------------ | ---------- | --------------------------------------- |
| `dataset`    | (required) | Dataset path (without `.npz` extension) |
| `problem_id` | `1`        | Test sample index to visualize          |
| `resultdir`  | `results`  | Output directory                        |

**Output Files:**

```
results/comparison/
├── vanilla_{dataset}_{problem_id}.gif       # A* only
├── neural_astar_{dataset}_{problem_id}.gif  # Neural A* only
├── ours_{dataset}_{problem_id}.gif          # Ours only
└── comparison_{dataset}_{problem_id}.gif    # 3-model comparison (Side-by-Side)
```

> **Note**: Time shown in GIF headers is pure inference time (ms), and Steps is the number of A\* search iterations.

---

## Experimental Results

### mixed_064_moore_c16_ours (64x64 Mixed Maze, 400 Test Samples)

| Model      | Opt (%) | Exp (%) | Hmean | Infer Time (ms) |
| ---------- | ------- | ------- | ----- | --------------- |
| Vanilla    | 100.00  | 0.00    | 0.00  | 48.12           |
| Neural A\* | 49.75   | 34.72   | 40.90 | 26.01           |
| Ours       | 82.25   | 33.98   | 48.09 | 27.58           |

### mazes_032_moore_c8_ours (32x32 Maze, 100 Test Samples)

| Model      | Opt (%) | Exp (%) | Hmean | Infer Time (ms) |
| ---------- | ------- | ------- | ----- | --------------- |
| Vanilla    | 100.00  | 0.00    | 0.00  | 17.66           |
| Neural A\* | 81.00   | 42.97   | 56.15 | 9.95            |
| Ours       | 98.00   | 29.86   | 45.78 | 12.62           |

**Metrics Explanation:**

- **Opt (%)**: Optimal path achievement ratio (higher is better)
- **Exp (%)**: Search node reduction rate compared to Vanilla (higher is better)
- **Hmean**: Harmonic mean of Opt and Exp

---

## Reference

Ryo Yonetani, Tatsunori Taniai, Mohammadamin Barekatain, Mai Nishimura, Asako Kanezaki,
"Path Planning using Neural A\* Search", ICML, 2021
[[paper]](https://arxiv.org/abs/2009.07476) [[project page]](https://omron-sinicx.github.io/neural-astar/)

Kexin Ke, Zhengyu Li, Jian Yang, Huining Chen, Hao Wang, Xuan Tang, Xian Wei,
"Continuous Geodesic Self-Attention Models with Gated Fusion for Trajectory Prediction", IJCNN, 2024
[[paper]](https://ieeexplore.ieee.org/document/10650786)

Keenan Crane, Clarisse Weischedel, Max Wardetzky,
"The Heat Method for Distance Computation", ACM Transactions on Graphics, 2017
[[paper]](https://dl.acm.org/doi/10.1145/3131280)
